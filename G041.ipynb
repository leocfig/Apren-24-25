{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "from sklearn.feature_selection import f_classif\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading the dataset\n",
    "data = loadarff('diabetes.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "# Decoding the byte string class labels\n",
    "df['Outcome'] = df['Outcome'].str.decode('utf-8')\n",
    "\n",
    "# Separate the features from the target\n",
    "X = df.drop(columns=['Outcome'])        # Features (8 biological features)\n",
    "y = df['Outcome']                       # Target (normal/diabetes)\n",
    "\n",
    "# Using ANOVA to determine the input variables with the worst \n",
    "# and best discriminative power\n",
    "f_values = f_classif(X, y)[0]\n",
    "best_power = X.columns[f_values.argmax()]\n",
    "worst_power = X.columns[f_values.argmin()]\n",
    "\n",
    "print(f'The input variable with the best discriminative power is {best_power}')\n",
    "print(f'The input variable with the worst discriminative power is {worst_power}')\n",
    "\n",
    "\n",
    "# Plotting the class-conditional probability density function of each feature\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for the best discriminative feature\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.kdeplot(X[best_power][y == '0'], label='Normal', fill=True)\n",
    "sns.kdeplot(X[best_power][y == '1'], label='Diabetes', fill=True)\n",
    "plt.title(f'Class-Conditional PDF of {best_power}')\n",
    "plt.xlabel(best_power)\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Outcome')\n",
    "\n",
    "# Plot for the worst discriminative feature\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.kdeplot(X[worst_power][y == '0'], label='Normal', fill=True)\n",
    "sns.kdeplot(X[worst_power][y == '1'], label='Diabetes', fill=True)\n",
    "plt.title(f'Class-Conditional PDF of {worst_power}')\n",
    "plt.xlabel(worst_power)\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Outcome')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io.arff import loadarff\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "data = loadarff('diabetes.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "# Decoding the byte string class labels\n",
    "df['Outcome'] = df['Outcome'].str.decode('utf-8')\n",
    "\n",
    "# Separate the features from the target\n",
    "X = df.drop(columns=['Outcome'])        # Features (8 biological features)\n",
    "y = df['Outcome']                       # Target (normal/diabetes)\n",
    "\n",
    "# Define the parameters for the samples_split\n",
    "min_samples_splits = [2, 5,10, 20, 30, 50, 100]\n",
    "\n",
    "# Initialize lists to store the accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Stratified 80-20 training-testing split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=1)\n",
    "\n",
    "# \n",
    "for min_samples in min_samples_splits:\n",
    "    training_accs = []\n",
    "    testing_accs = []\n",
    "\n",
    "    # Run 10 times for averaging\n",
    "    for _ in range(10):\n",
    "\n",
    "        # Initialize a Decision Tree Classifier with the current number min_samples\n",
    "        classifier = DecisionTreeClassifier(min_samples_split=min_samples, random_state=1)\n",
    "\n",
    "        # Fit the model\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on training sets\n",
    "        train_pred = classifier.predict(X_train)\n",
    "\n",
    "        # Predict on testing sets\n",
    "        test_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Calculate accuracies\n",
    "        training_acc = accuracy_score(y_train, train_pred)\n",
    "        testing_acc = accuracy_score(y_test, test_pred)\n",
    "        \n",
    "        # Store accuracies\n",
    "        training_accs.append(training_acc)\n",
    "        testing_accs.append(testing_acc)\n",
    "    \n",
    "    # Average accuracies for current min_samples_split\n",
    "\n",
    "    # Calculate mean for training accuracies\n",
    "    train_mean = sum(training_accs) / len(training_accs) if training_accs else 0\n",
    "    train_accuracies.append(train_mean)\n",
    "\n",
    "    # Calculate mean for testing accuracies\n",
    "    test_mean = sum(testing_accs) / len(testing_accs) if testing_accs else 0\n",
    "    test_accuracies.append(test_mean)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(min_samples_splits, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(min_samples_splits, test_accuracies, label='Testing Accuracy')\n",
    "plt.title('Training and Testing Accuracies vs Minimum Samples Split')\n",
    "plt.xlabel('Minimum Samples Split')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Stops elements from being cut off\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree, DecisionTreeClassifier\n",
    "from scipy.io.arff import loadarff\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "data = loadarff('diabetes.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "# Decoding the byte string class labels\n",
    "df['Outcome'] = df['Outcome'].str.decode('utf-8')\n",
    "\n",
    "# Separate the features from the target\n",
    "X = df.drop(columns=['Outcome'])        # Features (8 biological features)\n",
    "y = df['Outcome']                       # Target (normal/diabetes)\n",
    "\n",
    "# Initialize a Decision Tree Classifier with the required maximum depth\n",
    "classifier = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_tree(classifier, feature_names=X.columns, class_names=['Normal', 'Diabetes'], impurity=False)\n",
    "plt.title('Diabetes Decision Tree')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
